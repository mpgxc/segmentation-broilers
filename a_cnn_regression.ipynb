{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38bc11b6-758c-4eff-a5e3-12c4fb94832e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-01 04:08:16.818204: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-01 04:08:16.818222: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from glob import glob\n",
    "from skimage.io import imread\n",
    "from tqdm import tqdm \n",
    "from sklearn.model_selection import train_test_split\n",
    "from commons import plot\n",
    "from sklearn import metrics\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da32d0ea-c591-4b29-bbe8-d0021206716c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_evaluate(true, predicted):  \n",
    "    \n",
    "    mae = metrics.mean_absolute_error(true, predicted)\n",
    "    mse = metrics.mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n",
    "    r2_square = metrics.r2_score(true, predicted)\n",
    "    \n",
    "    print('MAE:', mae)\n",
    "    print('MSE:', mse)\n",
    "    print('RMSE:', rmse)\n",
    "    print('R2 Square', r2_square)\n",
    "    \n",
    "def rescale_arr(arr, scale=255):\n",
    "    return (arr * scale).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c4bccee-2efe-4c7e-9128-807849c20bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image | anilha | peso\n",
    "broilers_weights = pd.read_csv('feature_processing/galinhas_pesos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "724702f2-661d-4e7d-95f9-d72beeff246f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "def open_images(idx):\n",
    "    \n",
    "    folder_images = glob(f'images_cropped/images/{idx}/*')\n",
    "   \n",
    "    size_folder = len(folder_images) \n",
    "    index_image = randint(0, size_folder)\n",
    "\n",
    "    image =  folder_images[index_image]\n",
    "    \n",
    "    return imread(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa4c01f8-81ec-431b-8958-252b32f229a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = list(map(lambda x: x.split('/')[2], glob(\"images_cropped/images/*\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "554a030b-21c6-4285-961b-7e7c5c720215",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 25/25 [00:00<00:00, 529.84it/s]\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "anilhas = []\n",
    "\n",
    "for index in tqdm(all_images):\n",
    "    try:\n",
    "        img_resized = resize(open_images(index), (224, 224))\n",
    "        img = rescale_arr(img_resized)\n",
    "        images.append(img)\n",
    "        anilhas.append(int(index))\n",
    "    except: \n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0536ecb8-9b04-4b2c-92a7-6c6b2ff2b411",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [None] * len(anilhas)\n",
    "\n",
    "for anilha, peso in zip(broilers_weights.anilha,  broilers_weights.peso):\n",
    "    try:\n",
    "        weights[anilhas.index(anilha)] = peso\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59f34b2f-48e7-4f29-83fa-8fc245e62c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.asarray(images)\n",
    "weights = np.asarray(weights)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, weights, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc204f09-504b-4118-88a5-7e7b5c76ab1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = images[0].shape + (1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63521163-32db-46d9-bf50-6b2ac57046d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-01 04:08:18.200583: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-05-01 04:08:18.200603: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-05-01 04:08:18.200617: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (me): /proc/driver/nvidia/version does not exist\n",
      "2022-05-01 04:08:18.200804: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        \n",
    "        keras.layers.Conv2D(16,\n",
    "                            kernel_size=(3, 3),\n",
    "                            padding=\"same\",\n",
    "                            activation=\"relu\"),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        keras.layers.Conv2D(32,\n",
    "                            kernel_size=(3, 3), \n",
    "                            padding=\"same\", \n",
    "                            activation=\"relu\"),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        keras.layers.Conv2D(64,\n",
    "                            kernel_size=(3, 3), \n",
    "                            padding=\"same\",\n",
    "                            activation=\"relu\"),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(1, activation=\"linear\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db77e140-d258-46a6-8b46-4de4ba948171",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(0.0001)\n",
    "\n",
    "model.compile(loss='mse',  optimizer=optimizer,  metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55ec9af7-99d4-4d01-bb52-59631ac30331",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "10/10 [==============================] - 1s 34ms/step - loss: 2082449.6250 - mae: 1419.5836 - val_loss: 3228639.5000 - val_mae: 1756.7715\n",
      "Epoch 2/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1401765.0000 - mae: 1153.3713 - val_loss: 2084403.2500 - val_mae: 1389.9641\n",
      "Epoch 3/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 647776.3750 - mae: 701.2473 - val_loss: 816753.5000 - val_mae: 792.4425\n",
      "Epoch 4/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 199847.2031 - mae: 356.8109 - val_loss: 297140.7812 - val_mae: 423.3367\n",
      "Epoch 5/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 193635.0156 - mae: 349.9789 - val_loss: 317996.9062 - val_mae: 408.1784\n",
      "Epoch 6/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 137362.9062 - mae: 309.9703 - val_loss: 472710.1875 - val_mae: 510.3186\n",
      "Epoch 7/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 143211.2812 - mae: 306.7093 - val_loss: 497270.4375 - val_mae: 537.0295\n",
      "Epoch 8/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 126468.4531 - mae: 279.8631 - val_loss: 421524.0938 - val_mae: 455.1493\n",
      "Epoch 9/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 117338.0234 - mae: 289.0508 - val_loss: 373814.1875 - val_mae: 418.1151\n",
      "Epoch 10/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 115501.9375 - mae: 289.3883 - val_loss: 397384.1875 - val_mae: 434.1338\n",
      "Epoch 11/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 119006.7734 - mae: 299.3402 - val_loss: 386058.3125 - val_mae: 424.6107\n",
      "Epoch 12/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 115506.4609 - mae: 286.3409 - val_loss: 426719.5000 - val_mae: 462.8679\n",
      "Epoch 13/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 103274.3047 - mae: 260.5545 - val_loss: 420677.3438 - val_mae: 456.1266\n",
      "Epoch 14/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 103438.3594 - mae: 269.6878 - val_loss: 374814.6562 - val_mae: 418.9828\n",
      "Epoch 15/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 103541.1328 - mae: 276.0775 - val_loss: 435312.4062 - val_mae: 473.7153\n",
      "Epoch 16/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 101351.2188 - mae: 265.0643 - val_loss: 382363.8438 - val_mae: 425.3094\n",
      "Epoch 17/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 96868.1797 - mae: 251.5469 - val_loss: 436772.8438 - val_mae: 476.1093\n",
      "Epoch 18/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 88824.0391 - mae: 241.1706 - val_loss: 402720.3125 - val_mae: 448.0877\n",
      "Epoch 19/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 81608.4609 - mae: 236.1310 - val_loss: 370394.6562 - val_mae: 431.5508\n",
      "Epoch 20/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 83927.0859 - mae: 230.7238 - val_loss: 454502.6875 - val_mae: 495.5264\n",
      "Epoch 21/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 76270.0703 - mae: 223.2195 - val_loss: 410588.4375 - val_mae: 470.2046\n",
      "Epoch 22/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 71574.3906 - mae: 215.7032 - val_loss: 406296.0000 - val_mae: 472.1050\n",
      "Epoch 23/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 81090.0000 - mae: 216.3417 - val_loss: 479986.5625 - val_mae: 528.3698\n",
      "Epoch 24/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 64516.3438 - mae: 203.5491 - val_loss: 359090.3750 - val_mae: 447.0389\n",
      "Epoch 25/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 65251.0195 - mae: 200.5232 - val_loss: 462220.0938 - val_mae: 529.2350\n",
      "Epoch 26/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 58191.0195 - mae: 170.3128 - val_loss: 464584.0000 - val_mae: 537.6776\n",
      "Epoch 27/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 60020.2188 - mae: 198.3344 - val_loss: 377547.0625 - val_mae: 476.7767\n",
      "Epoch 28/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 46940.3828 - mae: 153.7590 - val_loss: 522325.0000 - val_mae: 584.5035\n",
      "Epoch 29/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 43685.9023 - mae: 135.8925 - val_loss: 472527.0938 - val_mae: 560.3798\n",
      "Epoch 30/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 38967.1367 - mae: 153.5930 - val_loss: 414824.1562 - val_mae: 523.9697\n",
      "Epoch 31/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 42032.2266 - mae: 166.6354 - val_loss: 497013.8438 - val_mae: 584.1167\n",
      "Epoch 32/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 38599.1797 - mae: 149.8953 - val_loss: 451630.0000 - val_mae: 560.8912\n",
      "Epoch 33/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 32801.4961 - mae: 131.8978 - val_loss: 471633.0938 - val_mae: 580.0938\n",
      "Epoch 34/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 29484.8340 - mae: 119.1318 - val_loss: 463632.8125 - val_mae: 578.0607\n",
      "Epoch 35/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 25902.4824 - mae: 128.9230 - val_loss: 513077.9375 - val_mae: 616.3762\n",
      "Epoch 36/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 25649.5273 - mae: 114.4372 - val_loss: 506121.6875 - val_mae: 613.3351\n",
      "Epoch 37/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 19692.1406 - mae: 110.7698 - val_loss: 498587.0938 - val_mae: 611.1735\n",
      "Epoch 38/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 22283.4648 - mae: 112.7639 - val_loss: 513388.9062 - val_mae: 622.8701\n",
      "Epoch 39/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 23295.8320 - mae: 104.5310 - val_loss: 545861.7500 - val_mae: 645.1181\n",
      "Epoch 40/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 22538.5352 - mae: 105.5002 - val_loss: 514266.9062 - val_mae: 627.9837\n",
      "Epoch 41/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 17512.0254 - mae: 103.9242 - val_loss: 531869.3125 - val_mae: 639.5430\n",
      "Epoch 42/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 18673.9629 - mae: 95.0276 - val_loss: 523921.5625 - val_mae: 633.3472\n",
      "Epoch 43/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 23512.7070 - mae: 114.1580 - val_loss: 517202.5625 - val_mae: 628.1066\n",
      "Epoch 44/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 12806.3330 - mae: 77.5303 - val_loss: 529840.0000 - val_mae: 637.3414\n",
      "Epoch 45/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 16652.2617 - mae: 93.8960 - val_loss: 509705.5938 - val_mae: 625.2767\n",
      "Epoch 46/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 16169.4043 - mae: 90.7430 - val_loss: 538120.6250 - val_mae: 644.6281\n",
      "Epoch 47/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 17147.1719 - mae: 97.2064 - val_loss: 559401.6250 - val_mae: 655.7627\n",
      "Epoch 48/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 17765.5000 - mae: 109.2217 - val_loss: 504748.5000 - val_mae: 624.1671\n",
      "Epoch 49/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 14363.2842 - mae: 90.3720 - val_loss: 563149.6250 - val_mae: 660.4633\n",
      "Epoch 50/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 15042.9629 - mae: 94.0973 - val_loss: 488354.3438 - val_mae: 612.9277\n",
      "Epoch 51/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 11732.6816 - mae: 88.8869 - val_loss: 495674.5000 - val_mae: 616.6608\n",
      "Epoch 52/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 11284.5508 - mae: 82.0218 - val_loss: 563743.7500 - val_mae: 659.6692\n",
      "Epoch 53/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 14030.3301 - mae: 89.0973 - val_loss: 520838.6562 - val_mae: 635.8895\n",
      "Epoch 54/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 9852.9199 - mae: 78.0454 - val_loss: 496906.0000 - val_mae: 620.6472\n",
      "Epoch 55/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 10020.2793 - mae: 77.2310 - val_loss: 512431.6875 - val_mae: 628.7717\n",
      "Epoch 56/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 10488.6738 - mae: 79.3792 - val_loss: 498080.4375 - val_mae: 616.6914\n",
      "Epoch 57/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 10236.6113 - mae: 80.1092 - val_loss: 495154.4062 - val_mae: 615.1774\n",
      "Epoch 58/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 10951.0332 - mae: 72.0923 - val_loss: 558168.3125 - val_mae: 654.0074\n",
      "Epoch 59/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 5929.8262 - mae: 55.2376 - val_loss: 501932.6562 - val_mae: 620.8996\n",
      "Epoch 60/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 8022.6812 - mae: 66.7801 - val_loss: 468264.5625 - val_mae: 600.3141\n",
      "Epoch 61/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 8702.7842 - mae: 77.8574 - val_loss: 537345.8750 - val_mae: 647.3016\n",
      "Epoch 62/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 10352.2568 - mae: 78.9499 - val_loss: 480929.6562 - val_mae: 608.5452\n",
      "Epoch 63/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 6986.7471 - mae: 67.1904 - val_loss: 484832.3438 - val_mae: 608.7637\n",
      "Epoch 64/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 7164.1924 - mae: 69.9016 - val_loss: 509282.6875 - val_mae: 626.2999\n",
      "Epoch 65/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 6980.9365 - mae: 73.8982 - val_loss: 457696.6562 - val_mae: 589.8872\n",
      "Epoch 66/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 4481.9712 - mae: 51.2354 - val_loss: 507802.5938 - val_mae: 621.1871\n",
      "Epoch 67/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 5584.6685 - mae: 55.5711 - val_loss: 502709.8438 - val_mae: 619.2941\n",
      "Epoch 68/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 5232.0771 - mae: 57.7671 - val_loss: 526783.0625 - val_mae: 633.6459\n",
      "Epoch 69/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2400.5466 - mae: 41.4007 - val_loss: 487976.0938 - val_mae: 615.2805\n",
      "Epoch 70/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 4176.8481 - mae: 53.3293 - val_loss: 553648.3750 - val_mae: 656.5695\n",
      "Epoch 71/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 4839.8105 - mae: 59.0853 - val_loss: 532175.8125 - val_mae: 643.9501\n",
      "Epoch 72/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 3694.0891 - mae: 51.2270 - val_loss: 485315.7500 - val_mae: 611.0013\n",
      "Epoch 73/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 5025.7354 - mae: 59.8698 - val_loss: 489505.3125 - val_mae: 615.0531\n",
      "Epoch 74/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 3204.2681 - mae: 46.2586 - val_loss: 516697.9375 - val_mae: 634.6998\n",
      "Epoch 75/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 4824.8340 - mae: 59.5668 - val_loss: 469035.0000 - val_mae: 600.8482\n",
      "Epoch 76/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2521.4109 - mae: 40.4358 - val_loss: 484963.3438 - val_mae: 608.4102\n",
      "Epoch 77/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1939.3538 - mae: 37.4597 - val_loss: 493928.5000 - val_mae: 616.4203\n",
      "Epoch 78/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2503.1704 - mae: 44.0867 - val_loss: 495370.1875 - val_mae: 619.5533\n",
      "Epoch 79/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2666.1812 - mae: 41.5863 - val_loss: 497997.7500 - val_mae: 621.6379\n",
      "Epoch 80/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1660.2269 - mae: 31.7636 - val_loss: 521040.5938 - val_mae: 636.6389\n",
      "Epoch 81/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2981.0056 - mae: 40.0326 - val_loss: 467303.5938 - val_mae: 602.8807\n",
      "Epoch 82/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2889.9854 - mae: 45.2625 - val_loss: 526874.9375 - val_mae: 639.7180\n",
      "Epoch 83/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1845.0570 - mae: 28.7377 - val_loss: 475232.5625 - val_mae: 605.5446\n",
      "Epoch 84/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2068.2334 - mae: 35.6215 - val_loss: 492819.3438 - val_mae: 617.0112\n",
      "Epoch 85/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 3313.3594 - mae: 43.5863 - val_loss: 509278.5938 - val_mae: 626.3654\n",
      "Epoch 86/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2551.9827 - mae: 45.5847 - val_loss: 471847.2500 - val_mae: 601.9969\n",
      "Epoch 87/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 3236.5825 - mae: 43.6555 - val_loss: 509115.1875 - val_mae: 628.6498\n",
      "Epoch 88/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 3991.3091 - mae: 50.6568 - val_loss: 537652.8750 - val_mae: 646.6082\n",
      "Epoch 89/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1815.3385 - mae: 32.7902 - val_loss: 510865.4375 - val_mae: 627.4727\n",
      "Epoch 90/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2889.1079 - mae: 42.9971 - val_loss: 511371.4375 - val_mae: 627.8353\n",
      "Epoch 91/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 4477.9048 - mae: 57.7623 - val_loss: 496741.6875 - val_mae: 622.2675\n",
      "Epoch 92/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1755.8297 - mae: 36.1535 - val_loss: 511197.8125 - val_mae: 630.7220\n",
      "Epoch 93/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2396.8755 - mae: 40.5417 - val_loss: 485957.6875 - val_mae: 613.0921\n",
      "Epoch 94/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 3368.9531 - mae: 45.8806 - val_loss: 512063.0938 - val_mae: 628.1178\n",
      "Epoch 95/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1609.9312 - mae: 32.6945 - val_loss: 486228.5000 - val_mae: 609.7379\n",
      "Epoch 96/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2956.8560 - mae: 43.7806 - val_loss: 523956.5625 - val_mae: 635.8207\n",
      "Epoch 97/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 963.9111 - mae: 25.9423 - val_loss: 513553.4062 - val_mae: 632.5002\n",
      "Epoch 98/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 4114.5181 - mae: 48.8666 - val_loss: 532753.8125 - val_mae: 645.2267\n",
      "Epoch 99/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2143.6323 - mae: 36.9809 - val_loss: 501448.9375 - val_mae: 624.8034\n",
      "Epoch 100/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2288.6587 - mae: 40.5661 - val_loss: 503874.6875 - val_mae: 624.8981\n",
      "Epoch 101/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1857.1514 - mae: 30.8949 - val_loss: 504497.1562 - val_mae: 621.5295\n",
      "Epoch 102/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1318.8889 - mae: 30.1048 - val_loss: 470203.5938 - val_mae: 598.7652\n",
      "Epoch 103/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1340.1304 - mae: 31.4649 - val_loss: 525013.8750 - val_mae: 631.0253\n",
      "Epoch 104/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1822.6957 - mae: 35.4881 - val_loss: 466200.4375 - val_mae: 593.7032\n",
      "Epoch 105/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1633.3835 - mae: 32.6746 - val_loss: 504963.5625 - val_mae: 616.1795\n",
      "Epoch 106/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 3199.4915 - mae: 42.1856 - val_loss: 496170.9375 - val_mae: 614.4335\n",
      "Epoch 107/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2781.6245 - mae: 43.2803 - val_loss: 511815.5000 - val_mae: 628.5459\n",
      "Epoch 108/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 3617.3250 - mae: 49.5538 - val_loss: 490146.1875 - val_mae: 617.8635\n",
      "Epoch 109/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2432.4497 - mae: 35.7119 - val_loss: 532377.3125 - val_mae: 641.4944\n",
      "Epoch 110/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 3840.4839 - mae: 48.3374 - val_loss: 450560.3125 - val_mae: 585.2008\n",
      "Epoch 111/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2927.7620 - mae: 44.2621 - val_loss: 546003.1250 - val_mae: 642.6442\n",
      "Epoch 112/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 4261.3320 - mae: 54.6630 - val_loss: 410354.3750 - val_mae: 550.8104\n",
      "Epoch 113/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2528.5112 - mae: 40.4254 - val_loss: 481961.5000 - val_mae: 598.6583\n",
      "Epoch 114/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 3675.6445 - mae: 51.0838 - val_loss: 472553.6562 - val_mae: 596.7209\n",
      "Epoch 115/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 3514.0417 - mae: 51.8050 - val_loss: 472203.1875 - val_mae: 599.2624\n",
      "Epoch 116/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2969.5186 - mae: 44.7586 - val_loss: 489581.9375 - val_mae: 610.5490\n",
      "Epoch 117/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1881.6373 - mae: 37.3937 - val_loss: 510332.1875 - val_mae: 623.2626\n",
      "Epoch 118/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1831.5759 - mae: 38.5990 - val_loss: 458862.5000 - val_mae: 594.4681\n",
      "Epoch 119/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2804.8801 - mae: 43.5915 - val_loss: 546555.4375 - val_mae: 650.8588\n",
      "Epoch 120/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 3122.9287 - mae: 45.1507 - val_loss: 490699.1875 - val_mae: 615.9080\n",
      "Epoch 121/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1955.7510 - mae: 37.5038 - val_loss: 513979.4062 - val_mae: 629.8259\n",
      "Epoch 122/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1364.3767 - mae: 27.9237 - val_loss: 497930.5000 - val_mae: 618.2406\n",
      "Epoch 123/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2177.5305 - mae: 33.1375 - val_loss: 495253.4062 - val_mae: 615.1769\n",
      "Epoch 124/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1869.9369 - mae: 32.5895 - val_loss: 518344.5000 - val_mae: 632.0467\n",
      "Epoch 125/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1499.9188 - mae: 31.9573 - val_loss: 482781.3125 - val_mae: 612.5953\n",
      "Epoch 126/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2080.8267 - mae: 34.6516 - val_loss: 520080.9062 - val_mae: 635.0209\n",
      "Epoch 127/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 3770.9441 - mae: 48.6919 - val_loss: 520926.9062 - val_mae: 633.0424\n",
      "Epoch 128/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1837.6829 - mae: 36.4320 - val_loss: 492108.0938 - val_mae: 614.4946\n",
      "Epoch 129/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1824.6077 - mae: 34.8263 - val_loss: 529419.1250 - val_mae: 636.2745\n",
      "Epoch 130/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 3729.3267 - mae: 49.6005 - val_loss: 497242.5000 - val_mae: 620.0082\n",
      "Epoch 131/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2259.9099 - mae: 37.6792 - val_loss: 442592.4062 - val_mae: 585.7877\n",
      "Epoch 132/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 3207.3435 - mae: 44.4012 - val_loss: 542413.1250 - val_mae: 646.0161\n",
      "Epoch 133/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1025.0868 - mae: 24.3732 - val_loss: 494339.1875 - val_mae: 618.9141\n",
      "Epoch 134/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1769.7389 - mae: 35.8339 - val_loss: 508910.0000 - val_mae: 626.9472\n",
      "Epoch 135/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2186.0464 - mae: 36.4069 - val_loss: 471774.4375 - val_mae: 604.1810\n",
      "Epoch 136/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2884.0503 - mae: 38.2550 - val_loss: 541690.8750 - val_mae: 646.3901\n",
      "Epoch 137/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 4248.5396 - mae: 55.3447 - val_loss: 456374.0625 - val_mae: 591.0947\n",
      "Epoch 138/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2504.4470 - mae: 42.3023 - val_loss: 530724.9375 - val_mae: 639.2762\n",
      "Epoch 139/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2744.5459 - mae: 43.5781 - val_loss: 498399.5000 - val_mae: 621.1805\n",
      "Epoch 140/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1732.5240 - mae: 28.8245 - val_loss: 538700.8750 - val_mae: 641.4343\n",
      "Epoch 141/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2400.7280 - mae: 40.6592 - val_loss: 444156.3125 - val_mae: 580.7042\n",
      "Epoch 142/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2577.4443 - mae: 42.9044 - val_loss: 535521.6250 - val_mae: 641.9537\n",
      "Epoch 143/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2276.1389 - mae: 33.5966 - val_loss: 509970.7500 - val_mae: 626.7679\n",
      "Epoch 144/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1564.3265 - mae: 33.8008 - val_loss: 478373.1875 - val_mae: 605.1268\n",
      "Epoch 145/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1807.7051 - mae: 31.9397 - val_loss: 492980.7500 - val_mae: 614.5681\n",
      "Epoch 146/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1729.8020 - mae: 30.8531 - val_loss: 490628.2500 - val_mae: 612.1658\n",
      "Epoch 147/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1910.3000 - mae: 38.1654 - val_loss: 491086.1875 - val_mae: 610.8811\n",
      "Epoch 148/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2442.9673 - mae: 38.6014 - val_loss: 450836.0625 - val_mae: 586.0996\n",
      "Epoch 149/500\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 3027.4270 - mae: 44.4244 - val_loss: 500005.4062 - val_mae: 619.7757\n",
      "Epoch 150/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 4763.1035 - mae: 57.3388 - val_loss: 493323.4062 - val_mae: 611.0936\n",
      "Epoch 151/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2359.2524 - mae: 37.1020 - val_loss: 469643.3125 - val_mae: 594.1085\n",
      "Epoch 152/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1515.8289 - mae: 30.4843 - val_loss: 508340.3125 - val_mae: 620.4022\n",
      "Epoch 153/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2248.9099 - mae: 35.9516 - val_loss: 488845.9375 - val_mae: 610.5238\n",
      "Epoch 154/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1328.3617 - mae: 30.4706 - val_loss: 484477.8125 - val_mae: 608.9897\n",
      "Epoch 155/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1573.2639 - mae: 28.6316 - val_loss: 489244.4062 - val_mae: 612.3935\n",
      "Epoch 156/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2510.5591 - mae: 37.4553 - val_loss: 538416.1250 - val_mae: 641.2662\n",
      "Epoch 157/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1803.8503 - mae: 37.0848 - val_loss: 466931.6562 - val_mae: 597.0372\n",
      "Epoch 158/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 3257.6921 - mae: 48.0575 - val_loss: 493082.9062 - val_mae: 614.3948\n",
      "Epoch 159/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2941.9048 - mae: 45.5169 - val_loss: 474389.9062 - val_mae: 602.7964\n",
      "Epoch 160/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1459.1442 - mae: 28.8142 - val_loss: 511796.5938 - val_mae: 623.1426\n",
      "Epoch 161/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1857.4625 - mae: 34.6164 - val_loss: 477570.0938 - val_mae: 601.5657\n",
      "Epoch 162/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2058.4658 - mae: 38.2862 - val_loss: 489893.9375 - val_mae: 611.2675\n",
      "Epoch 163/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1390.4958 - mae: 30.9082 - val_loss: 505700.9062 - val_mae: 624.0844\n",
      "Epoch 164/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2238.4976 - mae: 36.4987 - val_loss: 496588.3438 - val_mae: 616.9632\n",
      "Epoch 165/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1594.6270 - mae: 35.1015 - val_loss: 463842.5625 - val_mae: 595.2531\n",
      "Epoch 166/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1343.6350 - mae: 30.9364 - val_loss: 511148.6875 - val_mae: 624.9715\n",
      "Epoch 167/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2396.0664 - mae: 39.8305 - val_loss: 466300.4375 - val_mae: 598.6088\n",
      "Epoch 168/500\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 1167.1790 - mae: 28.0335 - val_loss: 541377.6250 - val_mae: 643.3419\n",
      "Epoch 169/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 3182.2456 - mae: 45.1276 - val_loss: 464930.7500 - val_mae: 601.7758\n",
      "Epoch 170/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1475.3304 - mae: 26.1725 - val_loss: 536585.5000 - val_mae: 646.4479\n",
      "Epoch 171/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 3383.8066 - mae: 47.8503 - val_loss: 489409.9062 - val_mae: 615.2503\n",
      "Epoch 172/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2122.8179 - mae: 37.8161 - val_loss: 472857.5625 - val_mae: 600.4290\n",
      "Epoch 173/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2125.7737 - mae: 38.5874 - val_loss: 518629.3125 - val_mae: 628.1534\n",
      "Epoch 174/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2040.1246 - mae: 37.3677 - val_loss: 466929.6875 - val_mae: 597.4374\n",
      "Epoch 175/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2306.3345 - mae: 35.2944 - val_loss: 515485.7500 - val_mae: 626.5648\n",
      "Epoch 176/500\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 3617.9148 - mae: 50.1102 - val_loss: 441567.4375 - val_mae: 580.9984\n",
      "Epoch 177/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2827.4136 - mae: 44.4197 - val_loss: 521349.8438 - val_mae: 630.7253\n",
      "Epoch 178/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2690.4812 - mae: 43.8439 - val_loss: 460397.4062 - val_mae: 592.7758\n",
      "Epoch 179/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2280.3667 - mae: 38.8221 - val_loss: 520913.4062 - val_mae: 628.8761\n",
      "Epoch 180/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1970.7102 - mae: 35.4900 - val_loss: 475536.4375 - val_mae: 602.6986\n",
      "Epoch 181/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2477.5022 - mae: 33.8243 - val_loss: 482897.2500 - val_mae: 609.2711\n",
      "Epoch 182/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1759.1549 - mae: 31.1320 - val_loss: 524582.5625 - val_mae: 636.9915\n",
      "Epoch 183/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1590.6833 - mae: 30.6558 - val_loss: 520869.0000 - val_mae: 636.0759\n",
      "Epoch 184/500\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 1378.1316 - mae: 28.2106 - val_loss: 515448.8125 - val_mae: 632.3947\n",
      "Epoch 185/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1847.5706 - mae: 30.6057 - val_loss: 530102.0000 - val_mae: 638.7111\n",
      "Epoch 186/500\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 1042.8234 - mae: 27.7899 - val_loss: 493989.9062 - val_mae: 616.4094\n",
      "Epoch 187/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 725.0056 - mae: 22.5623 - val_loss: 516580.1875 - val_mae: 631.1170\n",
      "Epoch 188/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2832.1074 - mae: 42.7374 - val_loss: 455754.8438 - val_mae: 591.5817\n",
      "Epoch 189/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 3774.3984 - mae: 49.6358 - val_loss: 539974.6250 - val_mae: 640.9460\n",
      "Epoch 190/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2114.1064 - mae: 37.7933 - val_loss: 467766.0938 - val_mae: 598.9956\n",
      "Epoch 191/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1326.0774 - mae: 27.5667 - val_loss: 500022.6875 - val_mae: 619.6921\n",
      "Epoch 192/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2052.4683 - mae: 37.5119 - val_loss: 487128.1875 - val_mae: 611.1863\n",
      "Epoch 193/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1692.0660 - mae: 28.9371 - val_loss: 477190.6562 - val_mae: 603.3386\n",
      "Epoch 194/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1709.0159 - mae: 29.7172 - val_loss: 519636.0000 - val_mae: 630.1340\n",
      "Epoch 195/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 3252.9170 - mae: 40.8130 - val_loss: 510336.0625 - val_mae: 625.4438\n",
      "Epoch 196/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1780.1667 - mae: 34.7191 - val_loss: 497300.6562 - val_mae: 617.3403\n",
      "Epoch 197/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1095.0623 - mae: 26.2656 - val_loss: 544048.8750 - val_mae: 643.1847\n",
      "Epoch 198/500\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 1539.4113 - mae: 29.4954 - val_loss: 488590.9062 - val_mae: 611.7837\n",
      "Epoch 199/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2369.1689 - mae: 41.1511 - val_loss: 507020.4062 - val_mae: 623.7795\n",
      "Epoch 200/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2819.6660 - mae: 43.5400 - val_loss: 541206.1250 - val_mae: 642.0485\n",
      "Epoch 201/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2044.8914 - mae: 38.8019 - val_loss: 504046.5000 - val_mae: 623.5134\n",
      "Epoch 202/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1244.8367 - mae: 27.9940 - val_loss: 511429.8438 - val_mae: 625.8112\n",
      "Epoch 203/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 775.9713 - mae: 21.2953 - val_loss: 496292.9062 - val_mae: 614.5750\n",
      "Epoch 204/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1278.2909 - mae: 28.5609 - val_loss: 475872.7500 - val_mae: 598.9655\n",
      "Epoch 205/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2308.2793 - mae: 34.7893 - val_loss: 505410.6875 - val_mae: 619.4551\n",
      "Epoch 206/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 3895.1836 - mae: 49.6228 - val_loss: 534209.6875 - val_mae: 636.4535\n",
      "Epoch 207/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1803.8041 - mae: 36.7068 - val_loss: 459497.5000 - val_mae: 593.5157\n",
      "Epoch 208/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2209.3245 - mae: 37.8948 - val_loss: 530731.6250 - val_mae: 638.8720\n",
      "Epoch 209/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1554.7969 - mae: 32.7030 - val_loss: 491408.5625 - val_mae: 615.3041\n",
      "Epoch 210/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1666.5989 - mae: 31.1238 - val_loss: 518091.4375 - val_mae: 630.5045\n",
      "Epoch 211/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1542.0104 - mae: 28.0158 - val_loss: 503189.3125 - val_mae: 625.1880\n",
      "Epoch 212/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1767.4496 - mae: 33.8203 - val_loss: 486283.3125 - val_mae: 612.5376\n",
      "Epoch 213/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 977.8037 - mae: 26.4336 - val_loss: 494254.1562 - val_mae: 614.7020\n",
      "Epoch 214/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1938.7777 - mae: 33.5077 - val_loss: 506200.3125 - val_mae: 622.9955\n",
      "Epoch 215/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1571.7019 - mae: 33.4074 - val_loss: 468538.8125 - val_mae: 600.6183\n",
      "Epoch 216/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1616.8793 - mae: 32.0423 - val_loss: 515144.2500 - val_mae: 628.6508\n",
      "Epoch 217/500\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 2012.2488 - mae: 38.2915 - val_loss: 486996.0938 - val_mae: 614.6935\n",
      "Epoch 218/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1006.0668 - mae: 25.4775 - val_loss: 513595.6562 - val_mae: 631.0491\n",
      "Epoch 219/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1709.4812 - mae: 32.8731 - val_loss: 480353.0000 - val_mae: 608.2756\n",
      "Epoch 220/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1465.5436 - mae: 31.5940 - val_loss: 529775.8125 - val_mae: 635.8876\n",
      "Epoch 221/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 3619.6499 - mae: 43.5181 - val_loss: 491290.9375 - val_mae: 613.0189\n",
      "Epoch 222/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1298.5967 - mae: 27.5108 - val_loss: 512849.6562 - val_mae: 625.4166\n",
      "Epoch 223/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 3656.4351 - mae: 43.5908 - val_loss: 501304.9375 - val_mae: 616.8369\n",
      "Epoch 224/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1511.8937 - mae: 30.9564 - val_loss: 479528.6875 - val_mae: 604.7892\n",
      "Epoch 225/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2574.2778 - mae: 40.9739 - val_loss: 516859.7500 - val_mae: 627.2342\n",
      "Epoch 226/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2259.3013 - mae: 36.8463 - val_loss: 493891.9062 - val_mae: 611.8444\n",
      "Epoch 227/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1639.7045 - mae: 28.3049 - val_loss: 469249.5938 - val_mae: 596.8324\n",
      "Epoch 228/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2733.6492 - mae: 44.2405 - val_loss: 478765.6875 - val_mae: 605.5570\n",
      "Epoch 229/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 4301.4834 - mae: 53.1702 - val_loss: 566829.6875 - val_mae: 654.3142\n",
      "Epoch 230/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 4634.7944 - mae: 53.9073 - val_loss: 423655.8125 - val_mae: 565.6809\n",
      "Epoch 231/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 3442.8579 - mae: 41.5055 - val_loss: 529595.2500 - val_mae: 633.2869\n",
      "Epoch 232/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1098.5934 - mae: 26.1358 - val_loss: 484157.5938 - val_mae: 609.1340\n",
      "Epoch 233/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1530.9625 - mae: 31.0194 - val_loss: 560638.7500 - val_mae: 655.5877\n",
      "Epoch 234/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2675.3911 - mae: 44.6205 - val_loss: 468483.7500 - val_mae: 603.6334\n",
      "Epoch 235/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2008.2223 - mae: 34.8219 - val_loss: 503578.1562 - val_mae: 619.1639\n",
      "Epoch 236/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1798.7897 - mae: 34.5333 - val_loss: 491481.1875 - val_mae: 612.9222\n",
      "Epoch 237/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 923.1625 - mae: 25.1616 - val_loss: 481889.6875 - val_mae: 609.0856\n",
      "Epoch 238/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 3153.4587 - mae: 44.6677 - val_loss: 529865.2500 - val_mae: 638.4652\n",
      "Epoch 239/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 645.1044 - mae: 22.0288 - val_loss: 497263.7500 - val_mae: 616.8824\n",
      "Epoch 240/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1388.3392 - mae: 31.4153 - val_loss: 492009.9062 - val_mae: 615.8229\n",
      "Epoch 241/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1842.8539 - mae: 33.5417 - val_loss: 541580.6250 - val_mae: 645.9993\n",
      "Epoch 242/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1782.1155 - mae: 35.4492 - val_loss: 532767.0625 - val_mae: 642.4263\n",
      "Epoch 243/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 3129.4141 - mae: 44.4788 - val_loss: 475303.3438 - val_mae: 606.9214\n",
      "Epoch 244/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2528.8513 - mae: 41.3216 - val_loss: 516326.6875 - val_mae: 625.2568\n",
      "Epoch 245/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2048.0322 - mae: 34.6401 - val_loss: 500058.0000 - val_mae: 618.1921\n",
      "Epoch 246/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 892.7029 - mae: 25.8981 - val_loss: 494152.2500 - val_mae: 617.0292\n",
      "Epoch 247/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1782.9724 - mae: 36.3095 - val_loss: 466859.0000 - val_mae: 597.3744\n",
      "Epoch 248/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2310.1045 - mae: 33.3964 - val_loss: 509756.3125 - val_mae: 623.7045\n",
      "Epoch 249/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1598.9858 - mae: 31.5843 - val_loss: 487352.6875 - val_mae: 611.8770\n",
      "Epoch 250/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2581.0627 - mae: 38.0139 - val_loss: 521864.3125 - val_mae: 629.2961\n",
      "Epoch 251/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2223.4753 - mae: 36.7096 - val_loss: 515458.4375 - val_mae: 629.1986\n",
      "Epoch 252/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1773.4485 - mae: 33.5001 - val_loss: 512209.9062 - val_mae: 631.4200\n",
      "Epoch 253/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1944.3201 - mae: 31.9283 - val_loss: 487490.0625 - val_mae: 616.0089\n",
      "Epoch 254/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2106.2527 - mae: 41.5230 - val_loss: 516969.5625 - val_mae: 630.2487\n",
      "Epoch 255/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2524.0632 - mae: 38.7902 - val_loss: 479048.8125 - val_mae: 610.4312\n",
      "Epoch 256/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2305.3589 - mae: 36.9042 - val_loss: 549761.8125 - val_mae: 649.2203\n",
      "Epoch 257/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1399.0010 - mae: 28.2216 - val_loss: 479227.7500 - val_mae: 602.4527\n",
      "Epoch 258/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 952.9129 - mae: 26.6393 - val_loss: 522353.4062 - val_mae: 627.6959\n",
      "Epoch 259/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 3431.4082 - mae: 45.8886 - val_loss: 514281.5625 - val_mae: 627.2048\n",
      "Epoch 260/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2964.7710 - mae: 43.5265 - val_loss: 501675.5000 - val_mae: 619.7897\n",
      "Epoch 261/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1594.2828 - mae: 34.1052 - val_loss: 517946.5938 - val_mae: 628.1566\n",
      "Epoch 262/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2319.6426 - mae: 37.3485 - val_loss: 512723.9375 - val_mae: 626.1487\n",
      "Epoch 263/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 3109.7705 - mae: 44.3771 - val_loss: 475952.0938 - val_mae: 605.9181\n",
      "Epoch 264/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1306.3479 - mae: 29.2175 - val_loss: 526964.8750 - val_mae: 636.1773\n",
      "Epoch 265/500\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 4545.6831 - mae: 55.5706 - val_loss: 525288.6875 - val_mae: 631.8537\n",
      "Epoch 266/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1852.2742 - mae: 36.8106 - val_loss: 457607.0625 - val_mae: 590.8541\n",
      "Epoch 267/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2925.0361 - mae: 42.3666 - val_loss: 555358.0000 - val_mae: 650.5298\n",
      "Epoch 268/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 4191.2104 - mae: 52.7329 - val_loss: 455191.9375 - val_mae: 594.5293\n",
      "Epoch 269/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 3244.8130 - mae: 45.1503 - val_loss: 527156.1875 - val_mae: 638.2684\n",
      "Epoch 270/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2473.5513 - mae: 36.4273 - val_loss: 532331.5000 - val_mae: 640.9948\n",
      "Epoch 271/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2124.9380 - mae: 29.6776 - val_loss: 533384.1250 - val_mae: 642.4559\n",
      "Epoch 272/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2836.1199 - mae: 42.0356 - val_loss: 496604.0000 - val_mae: 620.4933\n",
      "Epoch 273/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1936.0593 - mae: 34.6262 - val_loss: 537705.6875 - val_mae: 640.0768\n",
      "Epoch 274/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2485.1804 - mae: 37.9404 - val_loss: 513892.6562 - val_mae: 628.6545\n",
      "Epoch 275/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1355.4867 - mae: 29.8111 - val_loss: 512880.9062 - val_mae: 629.3054\n",
      "Epoch 276/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1466.7039 - mae: 30.2545 - val_loss: 534627.3125 - val_mae: 641.0576\n",
      "Epoch 277/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2047.8835 - mae: 36.2057 - val_loss: 473018.0000 - val_mae: 605.6553\n",
      "Epoch 278/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1081.4055 - mae: 27.6257 - val_loss: 550426.1250 - val_mae: 648.8749\n",
      "Epoch 279/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1414.4928 - mae: 31.7617 - val_loss: 474040.5938 - val_mae: 602.7587\n",
      "Epoch 280/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1875.0521 - mae: 36.7748 - val_loss: 541625.7500 - val_mae: 640.2417\n",
      "Epoch 281/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2224.4187 - mae: 37.8858 - val_loss: 523198.0938 - val_mae: 631.7887\n",
      "Epoch 282/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1673.0453 - mae: 33.8674 - val_loss: 488069.1562 - val_mae: 616.2484\n",
      "Epoch 283/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 3327.1023 - mae: 46.7735 - val_loss: 558836.3125 - val_mae: 654.6790\n",
      "Epoch 284/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2227.7302 - mae: 40.1496 - val_loss: 467533.5000 - val_mae: 597.9227\n",
      "Epoch 285/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 591.5396 - mae: 20.0185 - val_loss: 485604.9375 - val_mae: 607.3951\n",
      "Epoch 286/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1898.8508 - mae: 37.5405 - val_loss: 473194.5938 - val_mae: 601.0176\n",
      "Epoch 287/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2285.9790 - mae: 41.9426 - val_loss: 520821.1875 - val_mae: 626.0827\n",
      "Epoch 288/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2080.8508 - mae: 35.8456 - val_loss: 474043.8438 - val_mae: 602.8888\n",
      "Epoch 289/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2677.9429 - mae: 40.0732 - val_loss: 516066.3125 - val_mae: 631.4316\n",
      "Epoch 290/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1076.2205 - mae: 27.3196 - val_loss: 519924.3125 - val_mae: 635.8964\n",
      "Epoch 291/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2429.6892 - mae: 37.5402 - val_loss: 463119.5000 - val_mae: 601.5282\n",
      "Epoch 292/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2059.1694 - mae: 38.4902 - val_loss: 509458.0000 - val_mae: 628.1497\n",
      "Epoch 293/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1304.8821 - mae: 29.9776 - val_loss: 548057.3125 - val_mae: 650.6660\n",
      "Epoch 294/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2494.0884 - mae: 42.1446 - val_loss: 515826.2500 - val_mae: 631.5958\n",
      "Epoch 295/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1350.1687 - mae: 31.4176 - val_loss: 525366.0000 - val_mae: 635.8717\n",
      "Epoch 296/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2734.9880 - mae: 40.8399 - val_loss: 450472.9062 - val_mae: 591.3435\n",
      "Epoch 297/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1631.7070 - mae: 32.7954 - val_loss: 502748.6562 - val_mae: 622.1278\n",
      "Epoch 298/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2173.6941 - mae: 38.2341 - val_loss: 521505.8125 - val_mae: 634.7402\n",
      "Epoch 299/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2176.9180 - mae: 37.5081 - val_loss: 482035.0625 - val_mae: 610.4714\n",
      "Epoch 300/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2680.1960 - mae: 40.5487 - val_loss: 550637.4375 - val_mae: 644.3848\n",
      "Epoch 301/500\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 2746.5386 - mae: 45.6139 - val_loss: 501259.3125 - val_mae: 613.6129\n",
      "Epoch 302/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 3059.9617 - mae: 45.4555 - val_loss: 470759.5938 - val_mae: 600.1895\n",
      "Epoch 303/500\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 1360.1693 - mae: 27.7026 - val_loss: 531588.6875 - val_mae: 638.5406\n",
      "Epoch 304/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2090.0037 - mae: 34.0022 - val_loss: 496134.1875 - val_mae: 618.1522\n",
      "Epoch 305/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1770.8865 - mae: 31.6226 - val_loss: 490749.9062 - val_mae: 611.8535\n",
      "Epoch 306/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1350.0374 - mae: 29.1563 - val_loss: 488156.0625 - val_mae: 606.8558\n",
      "Epoch 307/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1451.6804 - mae: 28.4878 - val_loss: 471725.5625 - val_mae: 596.4999\n",
      "Epoch 308/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2907.4297 - mae: 44.5583 - val_loss: 480066.5938 - val_mae: 605.2966\n",
      "Epoch 309/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1270.3049 - mae: 28.8316 - val_loss: 495366.8125 - val_mae: 615.2881\n",
      "Epoch 310/500\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 2026.2246 - mae: 36.7297 - val_loss: 501266.4375 - val_mae: 619.4547\n",
      "Epoch 311/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1343.6121 - mae: 30.8595 - val_loss: 503769.0625 - val_mae: 624.2715\n",
      "Epoch 312/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1362.2631 - mae: 30.7493 - val_loss: 496169.3125 - val_mae: 618.1719\n",
      "Epoch 313/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1066.2166 - mae: 26.3073 - val_loss: 501231.6562 - val_mae: 617.1989\n",
      "Epoch 314/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2009.6387 - mae: 31.9650 - val_loss: 474682.8438 - val_mae: 598.3116\n",
      "Epoch 315/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2857.4353 - mae: 44.6417 - val_loss: 475043.2500 - val_mae: 597.6804\n",
      "Epoch 316/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 4168.3569 - mae: 53.9708 - val_loss: 562028.1250 - val_mae: 648.4113\n",
      "Epoch 317/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2384.4158 - mae: 41.0801 - val_loss: 449223.5000 - val_mae: 583.2508\n",
      "Epoch 318/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 3026.8655 - mae: 47.6298 - val_loss: 490942.5625 - val_mae: 609.0644\n",
      "Epoch 319/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1788.8093 - mae: 30.6079 - val_loss: 498107.6875 - val_mae: 613.2713\n",
      "Epoch 320/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1792.6110 - mae: 36.7115 - val_loss: 496443.0000 - val_mae: 612.8456\n",
      "Epoch 321/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1652.2819 - mae: 35.4440 - val_loss: 480426.3125 - val_mae: 607.4258\n",
      "Epoch 322/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2265.5083 - mae: 35.4589 - val_loss: 510131.5625 - val_mae: 626.0958\n",
      "Epoch 323/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1075.3468 - mae: 22.3509 - val_loss: 514309.9062 - val_mae: 628.4615\n",
      "Epoch 324/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1456.1075 - mae: 32.5034 - val_loss: 485034.8125 - val_mae: 611.7018\n",
      "Epoch 325/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2030.9928 - mae: 36.1312 - val_loss: 469585.5938 - val_mae: 598.0651\n",
      "Epoch 326/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 756.0509 - mae: 21.0561 - val_loss: 482255.9062 - val_mae: 604.9331\n",
      "Epoch 327/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1620.9973 - mae: 32.1591 - val_loss: 470649.6875 - val_mae: 599.9180\n",
      "Epoch 328/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1651.2227 - mae: 29.6191 - val_loss: 489670.6875 - val_mae: 613.0414\n",
      "Epoch 329/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1585.9318 - mae: 34.7886 - val_loss: 500844.5938 - val_mae: 615.7666\n",
      "Epoch 330/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1741.0352 - mae: 30.5405 - val_loss: 504292.0938 - val_mae: 621.2658\n",
      "Epoch 331/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 998.2726 - mae: 24.3672 - val_loss: 483810.0938 - val_mae: 611.7165\n",
      "Epoch 332/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 3304.2097 - mae: 42.5946 - val_loss: 485417.0938 - val_mae: 609.6024\n",
      "Epoch 333/500\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 967.0991 - mae: 24.6503 - val_loss: 504850.1875 - val_mae: 619.5629\n",
      "Epoch 334/500\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 2172.6733 - mae: 39.5919 - val_loss: 489554.0938 - val_mae: 613.1294\n",
      "Epoch 335/500\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 1377.6459 - mae: 32.8919 - val_loss: 523144.8125 - val_mae: 631.0632\n",
      "Epoch 336/500\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 1271.5927 - mae: 31.6365 - val_loss: 507604.1562 - val_mae: 619.9603\n",
      "Epoch 337/500\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 1703.6790 - mae: 34.6144 - val_loss: 475573.4062 - val_mae: 602.5106\n",
      "Epoch 338/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2114.9609 - mae: 41.1424 - val_loss: 564591.5000 - val_mae: 653.2419\n",
      "Epoch 339/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1964.3314 - mae: 36.2928 - val_loss: 446039.0938 - val_mae: 585.8737\n",
      "Epoch 340/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1544.0291 - mae: 31.3939 - val_loss: 536844.8750 - val_mae: 638.2455\n",
      "Epoch 341/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2696.1667 - mae: 43.7467 - val_loss: 500073.8125 - val_mae: 617.6834\n",
      "Epoch 342/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2695.6040 - mae: 38.9946 - val_loss: 445502.1562 - val_mae: 585.1188\n",
      "Epoch 343/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 3386.1118 - mae: 49.8580 - val_loss: 526924.5000 - val_mae: 632.3216\n",
      "Epoch 344/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1541.9839 - mae: 30.7119 - val_loss: 519472.4375 - val_mae: 630.7422\n",
      "Epoch 345/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 891.4557 - mae: 25.4892 - val_loss: 527275.0625 - val_mae: 635.6552\n",
      "Epoch 346/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2929.6406 - mae: 43.8459 - val_loss: 552481.6250 - val_mae: 652.2482\n",
      "Epoch 347/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1926.2512 - mae: 37.3810 - val_loss: 487468.5938 - val_mae: 616.4012\n",
      "Epoch 348/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2361.1848 - mae: 40.3412 - val_loss: 512134.0625 - val_mae: 624.2429\n",
      "Epoch 349/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1440.6285 - mae: 27.4095 - val_loss: 489501.4062 - val_mae: 610.3838\n",
      "Epoch 350/500\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 1549.1947 - mae: 29.9908 - val_loss: 478280.5938 - val_mae: 606.8256\n",
      "Epoch 351/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2696.2322 - mae: 40.6581 - val_loss: 490732.5938 - val_mae: 610.9913\n",
      "Epoch 352/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 3562.0200 - mae: 45.7196 - val_loss: 537806.2500 - val_mae: 633.6906\n",
      "Epoch 353/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2965.8940 - mae: 47.0477 - val_loss: 519970.5000 - val_mae: 626.7342\n",
      "Epoch 354/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 4582.5928 - mae: 51.8104 - val_loss: 435400.8125 - val_mae: 579.1628\n",
      "Epoch 355/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 4814.9536 - mae: 58.0883 - val_loss: 570862.6875 - val_mae: 665.6854\n",
      "Epoch 356/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2712.2944 - mae: 45.2270 - val_loss: 546692.6250 - val_mae: 651.9775\n",
      "Epoch 357/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 3966.6785 - mae: 52.0965 - val_loss: 433596.4062 - val_mae: 580.3013\n",
      "Epoch 358/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2791.9099 - mae: 43.3230 - val_loss: 597929.8750 - val_mae: 670.7047\n",
      "Epoch 359/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 7563.8760 - mae: 74.1300 - val_loss: 457314.6875 - val_mae: 590.4935\n",
      "Epoch 360/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 3088.6084 - mae: 45.9681 - val_loss: 450114.6875 - val_mae: 585.7980\n",
      "Epoch 361/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2485.7905 - mae: 43.1489 - val_loss: 542170.9375 - val_mae: 641.1215\n",
      "Epoch 362/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2891.4014 - mae: 43.8431 - val_loss: 525489.6250 - val_mae: 636.2894\n",
      "Epoch 363/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2688.4282 - mae: 45.5874 - val_loss: 497346.0000 - val_mae: 620.6306\n",
      "Epoch 364/500\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 1386.1858 - mae: 30.9455 - val_loss: 490444.7500 - val_mae: 617.0773\n",
      "Epoch 365/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 926.8296 - mae: 22.5777 - val_loss: 501770.4062 - val_mae: 621.9684\n",
      "Epoch 366/500\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 1157.2863 - mae: 27.4997 - val_loss: 538877.4375 - val_mae: 640.6674\n",
      "Epoch 367/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2571.8037 - mae: 39.3199 - val_loss: 501406.5000 - val_mae: 620.3097\n",
      "Epoch 368/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1890.4343 - mae: 31.1529 - val_loss: 450540.3125 - val_mae: 588.5701\n",
      "Epoch 369/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2342.2429 - mae: 41.8534 - val_loss: 550183.0000 - val_mae: 648.0795\n",
      "Epoch 370/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2866.2017 - mae: 43.8847 - val_loss: 524489.6875 - val_mae: 638.1685\n",
      "Epoch 371/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 3669.1243 - mae: 48.2435 - val_loss: 463702.5938 - val_mae: 603.2120\n",
      "Epoch 372/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 3991.4675 - mae: 51.1008 - val_loss: 548307.3750 - val_mae: 646.6976\n",
      "Epoch 373/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2921.5540 - mae: 43.2710 - val_loss: 551581.6875 - val_mae: 649.7202\n",
      "Epoch 374/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 3372.4250 - mae: 48.9527 - val_loss: 478892.4062 - val_mae: 609.2609\n",
      "Epoch 375/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 3112.0757 - mae: 45.2934 - val_loss: 479429.1562 - val_mae: 609.0253\n",
      "Epoch 376/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2315.0144 - mae: 38.7007 - val_loss: 563329.0625 - val_mae: 656.5020\n",
      "Epoch 377/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 3650.6265 - mae: 54.0461 - val_loss: 501643.3438 - val_mae: 621.2372\n",
      "Epoch 378/500\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 2680.8965 - mae: 42.6000 - val_loss: 475306.6875 - val_mae: 607.3208\n",
      "Epoch 379/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1106.4596 - mae: 26.9648 - val_loss: 564612.0625 - val_mae: 658.9913\n",
      "Epoch 380/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2345.8298 - mae: 36.0333 - val_loss: 494655.0000 - val_mae: 619.1573\n",
      "Epoch 381/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1651.6234 - mae: 32.3867 - val_loss: 515576.0000 - val_mae: 627.4471\n",
      "Epoch 382/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1849.0820 - mae: 30.2817 - val_loss: 488918.5938 - val_mae: 609.7528\n",
      "Epoch 383/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 930.4131 - mae: 25.5429 - val_loss: 489693.8125 - val_mae: 605.2687\n",
      "Epoch 384/500\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 860.6540 - mae: 22.0505 - val_loss: 499706.6875 - val_mae: 610.2983\n",
      "Epoch 385/500\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 1350.4005 - mae: 29.3656 - val_loss: 502868.9062 - val_mae: 611.6141\n",
      "Epoch 386/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2039.4349 - mae: 31.9616 - val_loss: 436014.9062 - val_mae: 569.7861\n",
      "Epoch 387/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2927.6323 - mae: 42.4574 - val_loss: 495220.5938 - val_mae: 609.0290\n",
      "Epoch 388/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2090.6978 - mae: 32.1275 - val_loss: 535459.0000 - val_mae: 636.0901\n",
      "Epoch 389/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2062.3198 - mae: 38.2671 - val_loss: 471694.2500 - val_mae: 600.6034\n",
      "Epoch 390/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1630.5237 - mae: 34.9337 - val_loss: 471743.2500 - val_mae: 599.0660\n",
      "Epoch 391/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1459.4749 - mae: 30.6557 - val_loss: 498051.5000 - val_mae: 613.2045\n",
      "Epoch 392/500\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 2616.2407 - mae: 38.5539 - val_loss: 521310.5625 - val_mae: 627.2678\n",
      "Epoch 393/500\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 3186.9976 - mae: 47.3574 - val_loss: 448801.5000 - val_mae: 584.4160\n",
      "Epoch 394/500\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 2123.0911 - mae: 37.8697 - val_loss: 489370.8438 - val_mae: 603.3098\n",
      "Epoch 395/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1586.7494 - mae: 33.5392 - val_loss: 484979.7500 - val_mae: 598.3224\n",
      "Epoch 396/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 994.4165 - mae: 24.3381 - val_loss: 497488.4375 - val_mae: 608.7926\n",
      "Epoch 397/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 749.0984 - mae: 21.4592 - val_loss: 484882.4062 - val_mae: 604.4694\n",
      "Epoch 398/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1875.5912 - mae: 34.4201 - val_loss: 481754.9062 - val_mae: 604.0114\n",
      "Epoch 399/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 688.6664 - mae: 20.3307 - val_loss: 465483.1875 - val_mae: 593.5417\n",
      "Epoch 400/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1103.8290 - mae: 30.5792 - val_loss: 470931.5000 - val_mae: 596.9001\n",
      "Epoch 401/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2631.6626 - mae: 40.4948 - val_loss: 516733.7500 - val_mae: 624.8387\n",
      "Epoch 402/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2332.9370 - mae: 39.5794 - val_loss: 499945.5625 - val_mae: 613.3180\n",
      "Epoch 403/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1203.3766 - mae: 30.8215 - val_loss: 533770.9375 - val_mae: 631.9896\n",
      "Epoch 404/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1687.7230 - mae: 30.5755 - val_loss: 478584.1562 - val_mae: 603.6869\n",
      "Epoch 405/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1172.8687 - mae: 30.3381 - val_loss: 522247.7500 - val_mae: 631.6592\n",
      "Epoch 406/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1372.5723 - mae: 29.3279 - val_loss: 484101.0000 - val_mae: 611.0534\n",
      "Epoch 407/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2006.8057 - mae: 35.1149 - val_loss: 541354.3750 - val_mae: 647.2207\n",
      "Epoch 408/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1790.5762 - mae: 34.4382 - val_loss: 513785.6875 - val_mae: 629.3500\n",
      "Epoch 409/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1736.0051 - mae: 32.3281 - val_loss: 510967.0625 - val_mae: 621.1922\n",
      "Epoch 410/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2068.4910 - mae: 35.8019 - val_loss: 475920.6562 - val_mae: 600.3065\n",
      "Epoch 411/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2537.9927 - mae: 40.5899 - val_loss: 554929.1250 - val_mae: 650.6201\n",
      "Epoch 412/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 3640.9004 - mae: 49.5401 - val_loss: 519362.6875 - val_mae: 633.3552\n",
      "Epoch 413/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 3320.9082 - mae: 43.3551 - val_loss: 454800.9375 - val_mae: 589.2175\n",
      "Epoch 414/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1632.8966 - mae: 32.0713 - val_loss: 485619.0938 - val_mae: 605.6573\n",
      "Epoch 415/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 888.8705 - mae: 25.7455 - val_loss: 490539.0938 - val_mae: 608.4948\n",
      "Epoch 416/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1347.3588 - mae: 30.0418 - val_loss: 488680.2500 - val_mae: 609.5468\n",
      "Epoch 417/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 800.2111 - mae: 22.8409 - val_loss: 501005.5000 - val_mae: 616.1698\n",
      "Epoch 418/500\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 1128.6010 - mae: 27.6809 - val_loss: 489612.5938 - val_mae: 610.9930\n",
      "Epoch 419/500\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 3220.3452 - mae: 42.3159 - val_loss: 513183.5938 - val_mae: 628.8905\n",
      "Epoch 420/500\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 1698.3929 - mae: 34.8294 - val_loss: 464106.0938 - val_mae: 599.0298\n",
      "Epoch 421/500\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 1547.1139 - mae: 31.8316 - val_loss: 516090.8125 - val_mae: 627.3441\n",
      "Epoch 422/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1544.6082 - mae: 33.4086 - val_loss: 499112.6875 - val_mae: 616.1305\n",
      "Epoch 423/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 987.1693 - mae: 26.4413 - val_loss: 461477.2500 - val_mae: 592.3226\n",
      "Epoch 424/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1379.5676 - mae: 26.2856 - val_loss: 544858.2500 - val_mae: 639.3683\n",
      "Epoch 425/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1379.8655 - mae: 30.9183 - val_loss: 489903.6562 - val_mae: 610.9693\n",
      "Epoch 426/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1437.6150 - mae: 30.8572 - val_loss: 575718.1250 - val_mae: 661.9310\n",
      "Epoch 427/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 3182.4097 - mae: 44.6480 - val_loss: 493324.6562 - val_mae: 617.3417\n",
      "Epoch 428/500\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 2273.1499 - mae: 41.6085 - val_loss: 478677.9062 - val_mae: 608.4234\n",
      "Epoch 429/500\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 2417.7598 - mae: 38.7764 - val_loss: 505559.4062 - val_mae: 624.8389\n",
      "Epoch 430/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1021.1830 - mae: 25.1321 - val_loss: 513246.5625 - val_mae: 627.9946\n",
      "Epoch 431/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1120.6787 - mae: 26.9483 - val_loss: 463377.5625 - val_mae: 597.5387\n",
      "Epoch 432/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2388.6987 - mae: 36.5335 - val_loss: 543189.8125 - val_mae: 641.8552\n",
      "Epoch 433/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 3817.4526 - mae: 51.0673 - val_loss: 490246.0938 - val_mae: 609.9432\n",
      "Epoch 434/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1290.1478 - mae: 30.8140 - val_loss: 520358.0625 - val_mae: 628.4740\n",
      "Epoch 435/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1169.7451 - mae: 28.2191 - val_loss: 514312.7500 - val_mae: 625.4618\n",
      "Epoch 436/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 879.7227 - mae: 25.8878 - val_loss: 512923.7500 - val_mae: 622.8719\n",
      "Epoch 437/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1116.0210 - mae: 26.8016 - val_loss: 480529.0625 - val_mae: 602.7943\n",
      "Epoch 438/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 820.7466 - mae: 21.8721 - val_loss: 523679.4062 - val_mae: 627.4285\n",
      "Epoch 439/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 563.2588 - mae: 19.5775 - val_loss: 480939.6875 - val_mae: 605.0113\n",
      "Epoch 440/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1289.5182 - mae: 29.5134 - val_loss: 497058.5938 - val_mae: 612.3933\n",
      "Epoch 441/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 950.9841 - mae: 23.7703 - val_loss: 510646.8125 - val_mae: 619.6887\n",
      "Epoch 442/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1819.3002 - mae: 34.2436 - val_loss: 488445.3125 - val_mae: 610.4200\n",
      "Epoch 443/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1779.0502 - mae: 35.2497 - val_loss: 490367.0000 - val_mae: 610.8319\n",
      "Epoch 444/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1496.9293 - mae: 29.8447 - val_loss: 503814.9375 - val_mae: 615.3600\n",
      "Epoch 445/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1422.7422 - mae: 27.5587 - val_loss: 492038.4062 - val_mae: 608.3444\n",
      "Epoch 446/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 739.7049 - mae: 22.8071 - val_loss: 512071.1875 - val_mae: 622.8282\n",
      "Epoch 447/500\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 1207.3124 - mae: 31.6905 - val_loss: 488809.1875 - val_mae: 613.3833\n",
      "Epoch 448/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1865.8879 - mae: 33.8785 - val_loss: 529065.1875 - val_mae: 639.7094\n",
      "Epoch 449/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1530.4712 - mae: 32.5424 - val_loss: 519960.1562 - val_mae: 631.0126\n",
      "Epoch 450/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1227.1841 - mae: 26.8012 - val_loss: 505362.0938 - val_mae: 621.7804\n",
      "Epoch 451/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 946.5750 - mae: 23.8365 - val_loss: 536942.1875 - val_mae: 639.5625\n",
      "Epoch 452/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2481.9475 - mae: 41.9869 - val_loss: 494066.0938 - val_mae: 614.3266\n",
      "Epoch 453/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1072.3728 - mae: 27.4101 - val_loss: 484417.9062 - val_mae: 607.9429\n",
      "Epoch 454/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1238.7957 - mae: 27.9659 - val_loss: 506266.1562 - val_mae: 622.7455\n",
      "Epoch 455/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 730.1084 - mae: 20.0838 - val_loss: 543701.3750 - val_mae: 644.8646\n",
      "Epoch 456/500\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 1387.5863 - mae: 30.2703 - val_loss: 478678.6562 - val_mae: 607.8044\n",
      "Epoch 457/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2077.6729 - mae: 37.1410 - val_loss: 474381.0938 - val_mae: 602.7933\n",
      "Epoch 458/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1385.9205 - mae: 30.4827 - val_loss: 522643.7500 - val_mae: 627.2953\n",
      "Epoch 459/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1624.4189 - mae: 30.7214 - val_loss: 475571.9062 - val_mae: 601.7306\n",
      "Epoch 460/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1645.0984 - mae: 34.7869 - val_loss: 519031.9375 - val_mae: 626.4957\n",
      "Epoch 461/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 719.7329 - mae: 22.0500 - val_loss: 489836.1562 - val_mae: 611.6288\n",
      "Epoch 462/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 858.7765 - mae: 21.7368 - val_loss: 476233.4375 - val_mae: 605.6520\n",
      "Epoch 463/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2295.9526 - mae: 38.4383 - val_loss: 490643.9375 - val_mae: 613.1284\n",
      "Epoch 464/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1945.0291 - mae: 38.1386 - val_loss: 508049.8438 - val_mae: 621.1907\n",
      "Epoch 465/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1022.5070 - mae: 25.3803 - val_loss: 525701.1250 - val_mae: 633.7570\n",
      "Epoch 466/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1639.9264 - mae: 32.6340 - val_loss: 481496.5000 - val_mae: 609.8181\n",
      "Epoch 467/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1481.8440 - mae: 31.5545 - val_loss: 533678.1875 - val_mae: 637.1136\n",
      "Epoch 468/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2739.8506 - mae: 41.7510 - val_loss: 527583.6250 - val_mae: 631.6685\n",
      "Epoch 469/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1538.8677 - mae: 28.1071 - val_loss: 463730.3125 - val_mae: 593.7543\n",
      "Epoch 470/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 3455.9116 - mae: 50.6098 - val_loss: 551015.8750 - val_mae: 647.1828\n",
      "Epoch 471/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2063.6816 - mae: 34.2347 - val_loss: 490495.2500 - val_mae: 610.6492\n",
      "Epoch 472/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2071.3032 - mae: 38.4942 - val_loss: 459542.5938 - val_mae: 590.8383\n",
      "Epoch 473/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2098.7532 - mae: 37.8638 - val_loss: 529700.3750 - val_mae: 629.9551\n",
      "Epoch 474/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1443.3879 - mae: 29.2565 - val_loss: 503302.9375 - val_mae: 614.2397\n",
      "Epoch 475/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1626.3640 - mae: 34.1619 - val_loss: 513363.8125 - val_mae: 621.2428\n",
      "Epoch 476/500\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 605.1323 - mae: 18.7624 - val_loss: 483933.0000 - val_mae: 603.7772\n",
      "Epoch 477/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1341.1045 - mae: 30.7951 - val_loss: 481292.8125 - val_mae: 603.6855\n",
      "Epoch 478/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1135.0131 - mae: 27.7821 - val_loss: 522764.2500 - val_mae: 631.3782\n",
      "Epoch 479/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2225.0276 - mae: 39.5100 - val_loss: 506701.8125 - val_mae: 621.0764\n",
      "Epoch 480/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1313.5403 - mae: 31.4398 - val_loss: 520005.9375 - val_mae: 626.7984\n",
      "Epoch 481/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1954.4561 - mae: 36.7342 - val_loss: 487554.3125 - val_mae: 605.9503\n",
      "Epoch 482/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1640.3239 - mae: 30.5097 - val_loss: 449862.3125 - val_mae: 583.6512\n",
      "Epoch 483/500\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 1087.7517 - mae: 27.8422 - val_loss: 539936.7500 - val_mae: 638.1914\n",
      "Epoch 484/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1386.8372 - mae: 30.3770 - val_loss: 488070.5938 - val_mae: 610.8831\n",
      "Epoch 485/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2435.5256 - mae: 37.1298 - val_loss: 505708.0000 - val_mae: 619.0397\n",
      "Epoch 486/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2473.4292 - mae: 40.8477 - val_loss: 457422.4375 - val_mae: 586.1445\n",
      "Epoch 487/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1202.9041 - mae: 24.6835 - val_loss: 474204.9375 - val_mae: 593.5907\n",
      "Epoch 488/500\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 1178.9568 - mae: 29.0086 - val_loss: 466760.0000 - val_mae: 589.6672\n",
      "Epoch 489/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 693.8699 - mae: 20.3487 - val_loss: 482467.9375 - val_mae: 599.5640\n",
      "Epoch 490/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 875.8060 - mae: 23.6008 - val_loss: 476204.5625 - val_mae: 594.5792\n",
      "Epoch 491/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1574.4077 - mae: 33.3374 - val_loss: 497863.3438 - val_mae: 607.2402\n",
      "Epoch 492/500\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 988.7911 - mae: 24.7503 - val_loss: 485642.0000 - val_mae: 604.4984\n",
      "Epoch 493/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1985.8958 - mae: 33.9082 - val_loss: 512505.0625 - val_mae: 625.3446\n",
      "Epoch 494/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1656.4658 - mae: 31.7150 - val_loss: 502337.8438 - val_mae: 618.6813\n",
      "Epoch 495/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1629.6428 - mae: 32.7029 - val_loss: 507628.0000 - val_mae: 616.2091\n",
      "Epoch 496/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 852.3986 - mae: 24.0429 - val_loss: 482954.5000 - val_mae: 602.1164\n",
      "Epoch 497/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1548.4058 - mae: 33.6210 - val_loss: 488735.8438 - val_mae: 604.6925\n",
      "Epoch 498/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 2124.6753 - mae: 38.0459 - val_loss: 464952.0625 - val_mae: 590.5322\n",
      "Epoch 499/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1734.2312 - mae: 31.1071 - val_loss: 469702.5000 - val_mae: 597.9551\n",
      "Epoch 500/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1694.5475 - mae: 31.6203 - val_loss: 516730.1875 - val_mae: 629.3226\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9a9c2c4310>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          batch_size=2,\n",
    "          validation_data=[X_test, y_test],\n",
    "          epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e79469-ed9f-441a-a7f1-884b1a5dbaee",
   "metadata": {},
   "source": [
    "## - - Treino - -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0528f384-a613-4256-9467-151ed4bebcf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 19.526373291015624\n",
      "MSE: 591.4110487349332\n",
      "RMSE: 24.318944235614612\n",
      "R2 Square 0.9902729449834226\n"
     ]
    }
   ],
   "source": [
    "print_evaluate(y_train, model.predict(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3724b718-d69d-4c2d-a8bc-ed9b7a1e7554",
   "metadata": {},
   "source": [
    "## - - Teste - -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b29b3df3-e408-41da-a29c-e06b6e7a386f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 629.3229736328125\n",
      "MSE: 516730.7703458816\n",
      "RMSE: 718.8398780993452\n",
      "R2 Square -2.650641422993373\n"
     ]
    }
   ],
   "source": [
    "print_evaluate(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3881d2e3-8409-4295-9f95-09a05c591e61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
